use diesel::prelude::*;
use log::{info, warn};
use nix::sys::signal::{self, Signal};
use nix::unistd::Pid;
use std::fmt;
use std::sync::Arc;
use std::time::Duration;
use tokio::task;
use uuid::Uuid;

use object_store::ObjectStore;

use crate::DbPool;
use common::models::{Exploit, ExploitStatus};
use deadpool_lapin::lapin::{options::BasicPublishOptions, BasicProperties};

const BUILD_MEMORY: &str = "2g";
const BUILD_CPU: f32 = 1.0;
const BUILD_DISK: &str = "20g";
const BUILD_MAX_SECONDS: u64 = 120;
const MAX_RETRIES: usize = 5;

pub enum BuildError {
    ErrorRetry(String),
    ErrorFail(String),
}

impl fmt::Display for BuildError {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        match self {
            BuildError::ErrorRetry(err) => write!(f, "{}", err),
            BuildError::ErrorFail(err) => write!(f, "{}", err),
        }
    }
}

fn fetch_exploit(exploit_uuid: Uuid, db_pool: &DbPool) -> Result<Exploit, BuildError> {
    use common::schema::exploits::dsl::*;
    let mut conn = db_pool
        .get()
        .map_err(|err| BuildError::ErrorRetry(err.to_string()))?;
    match exploits
        .filter(exploit_id.eq(exploit_uuid))
        .first::<Exploit>(&mut conn)
        .optional()
        .map_err(|err| BuildError::ErrorRetry(err.to_string()))?
    {
        Some(exploit) => Ok(exploit),
        None => Err(BuildError::ErrorFail(format!(
            "Unable to find exploit with id {exploit_uuid}"
        ))),
    }
}

fn update_exploit_building(exploit: &Exploit, db_pool: &DbPool) -> Result<(), BuildError> {
    use common::schema::exploits::dsl::*;
    let mut conn = db_pool
        .get()
        .map_err(|err| BuildError::ErrorRetry(err.to_string()))?;
    diesel::update(&exploit)
        .set(status.eq(ExploitStatus::Building))
        .execute(&mut conn)
        .map_err(|err| BuildError::ErrorRetry(err.to_string()))?;
    Ok(())
}

fn update_exploit_built(
    exploit: &Exploit,
    build_success: bool,
    db_pool: &DbPool,
) -> Result<(), BuildError> {
    use common::schema::exploits::dsl::*;
    let mut conn = db_pool
        .get()
        .map_err(|err| BuildError::ErrorRetry(err.to_string()))?;

    let update = diesel::update(&exploit);
    let update = if build_success {
        update.set((status.eq(ExploitStatus::BuildOk), pending.eq(Some(true))))
    } else {
        update.set((
            status.eq(ExploitStatus::BuildFailed),
            pending.eq(None::<bool>),
        ))
    };
    update
        .execute(&mut conn)
        .map_err(|err| BuildError::ErrorRetry(err.to_string()))?;
    Ok(())
}

async fn do_build_exploit_kaniko(
    exploit: &Exploit,
    object_store: &Arc<dyn ObjectStore>,
    object_store_url_prefix: &str,
    disk_limit_available: bool,
    exploit_docker_repo: &str,
    container_runner: &str,
) -> Result<bool, BuildError> {
    let image_tag = &format!("{}{}:latest", exploit_docker_repo, exploit.archive_id());
    let archive_path = object_store::path::Path::from(format!("{}.tar.gz", exploit.archive_id()));
    let exploit_archive_meta = object_store.head(&archive_path).await.map_err(|err| {
        BuildError::ErrorFail(format!(
            "Exploit {}, Failed to retrieve exploit metadata: {}",
            exploit.exploit_id(),
            err
        ))
    })?;

    // TODO(P2): improve the exploit path handling
    let context_url = if object_store_url_prefix.starts_with('/') {
        format!(
            "tar://{}{}",
            object_store_url_prefix, exploit_archive_meta.location
        )
    } else {
        format!(
            "{}{}",
            object_store_url_prefix, exploit_archive_meta.location
        )
    };
    info!("Exploit location: {}", context_url);

    let mut exploit_build_command = async_process::Command::new(container_runner);

    exploit_build_command.args([
        "run",
        "--rm",
        &format!("--cpus={BUILD_CPU}"),
        &format!("--memory={BUILD_MEMORY}"),
        "--log-driver",
        "passthrough",
        "-e",
        "GOOGLE_APPLICATION_CREDENTIALS=/credentials/gcp.json",
        "-v",
        "/credentials:/credentials:ro",
    ]);

    if object_store_url_prefix.starts_with('/') {
        exploit_build_command.args([
            "-v",
            &format!("{object_store_url_prefix}:{object_store_url_prefix}:ro"),
        ]);
    }

    if disk_limit_available {
        exploit_build_command.args(["--storage-opt", &format!("size={BUILD_DISK}")]);
    } else {
        log::warn!("Not limiting available disk space for exploit build container");
    }

    exploit_build_command.args([
        "gcr.io/kaniko-project/executor:latest",
        "--destination",
        image_tag,
        "--insecure-registry",
        exploit_docker_repo,
        "--cache=true",
        "--context",
        context_url.as_ref(),
    ]);

    info!("Exploit build command {:?}", exploit_build_command);
    let mut exploit_build = exploit_build_command.spawn().map_err(|err| {
        BuildError::ErrorRetry(format!(
            "Exploit {}, failed to spawn Kaniko: {}",
            exploit.exploit_id(),
            err
        ))
    })?;

    let build_status = match tokio::time::timeout(
        Duration::from_secs(BUILD_MAX_SECONDS),
        exploit_build.status(),
    )
    .await
    {
        Err(err) => {
            match exploit_build.id().try_into() {
                Err(_) => {
                    log::warn!(
                        "Exploit {}, build time limit exceeded: {}, failed to get process pid",
                        exploit.exploit_id(),
                        err
                    );
                }
                Ok(pid) => {
                    match signal::kill(Pid::from_raw(pid), Signal::SIGTERM) {
                        Ok(()) => {
                            log::info!(
                                "Exploit {}, build time limit exceeded: {}",
                                exploit.exploit_id(),
                                err
                            );
                        }
                        Err(_) => {
                            log::warn!(
                                "Exploit {}, build time limit exceeded: {}, failed to kill process",
                                exploit.exploit_id(),
                                err
                            );
                        }
                    };
                }
            };

            false
        }
        Ok(exploit_build_res) => exploit_build_res
            .map_err(|err| {
                BuildError::ErrorRetry(format!(
                    "Exploit {}, failed to get exit status for Kaniko: {}",
                    exploit.exploit_id(),
                    err
                ))
            })?
            .success(),
    };

    Ok(build_status)
}

pub async fn build_exploit(
    exploit_uuid: Uuid,
    db_pool: &crate::DbPool,
    amqp_pool: &deadpool_lapin::Pool,
    object_store: &Arc<dyn ObjectStore>,
    object_store_url_prefix: &str,
    disk_limit_available: bool,
    exploit_docker_repo: &str,
    container_runner: &str,
) -> Result<(), BuildError> {
    info!("Build requested for exploit {}", exploit_uuid);

    let exploit_to_build = fetch_exploit(exploit_uuid, db_pool)?;
    if *exploit_to_build.status() == ExploitStatus::Cancelled {
        info!("Exploit with id {} cancelled, skipping build", exploit_uuid);
        return Ok(());
    }

    if *exploit_to_build.status() == ExploitStatus::BuildFailed {
        warn!(
            "Exploit with id {} already failed to build, not retrying",
            exploit_uuid
        );
        return Ok(());
    }

    info!("Going to build exploit {}", exploit_uuid);

    let new_build_status = if *exploit_to_build.status() == ExploitStatus::BuildOk {
        warn!(
            "Exploit with id {} already built, resubmitting to run queue",
            exploit_to_build.exploit_id()
        );
        true
    } else {
        update_exploit_building(&exploit_to_build, db_pool)?;

        // TODO(P2): make this less ugly
        let mut attempt = 0;
        let build_status = loop {
            attempt += 1;
            let build_result = task::block_in_place(|| {
                do_build_exploit_kaniko(
                    &exploit_to_build,
                    object_store,
                    object_store_url_prefix,
                    disk_limit_available,
                    exploit_docker_repo,
                    container_runner,
                )
            })
            .await;

            match build_result {
                Ok(build_status) => break Ok(build_status),
                Err(build_error) => {
                    if attempt < MAX_RETRIES {
                        continue;
                    } else {
                        update_exploit_built(&exploit_to_build, false, db_pool)?;
                        break Err(build_error);
                    }
                }
            }
        }?;

        update_exploit_built(&exploit_to_build, build_status, db_pool)?;
        build_status
    };

    if new_build_status {
        let connection = amqp_pool
            .get()
            .await
            .map_err(|err| BuildError::ErrorRetry(err.to_string()))?;
        let channel = connection
            .create_channel()
            .await
            .map_err(|err| BuildError::ErrorRetry(err.to_string()))?;
        channel
            .basic_publish(
                "",
                common::EXPLOIT_RUN_QUEUE,
                BasicPublishOptions::default(),
                exploit_to_build.exploit_id().as_bytes(),
                BasicProperties::default(),
            )
            .await
            .map_err(|err| BuildError::ErrorRetry(err.to_string()))?;
    }

    Ok(())
}
